# Vastiva - AI-Powered Media Converter

A production-ready, AI-enhanced media transcoding platform with intelligent optimization and natural language search.

## âœ¨ Features

### Core Capabilities
- **Job Queue System**: Concurrent processing with goroutine worker pool
- **Hardware Acceleration**: NVIDIA NVENC, Intel QSV, AMD VAAPI (Auto-detected)
- **Multi-Format Support**: H.265/HEVC encoding with 10-bit color depth
- **Real-time Monitoring**: Live progress tracking, FPS, and ETA calculation
- **Automated Scanner**: Watch directories for new media with multiple scan modes

### ğŸ¤– AI-Powered Features (Premium)
- **Adaptive Encoding**: AI analyzes media to select optimal CRF values
- **Smart Metadata**: Automatic filename cleaning and Title/Year extraction
- **Whisper Subtitles**: AI-generated speech-to-text transcription (OpenAI)
- **AI Upscaling**: Enhance videos to 1080p or 4K with intelligent scaling
- **Natural Language Search**: Find media using semantic queries
- **AI-Enhanced Dashboard**: Storage savings analytics and efficiency scoring

### ğŸ¨ Modern Web Interface
- **Premium Dashboard**: Glassmorphism design with real-time insights
- **Job Management**: Create, monitor, and cancel transcoding jobs
- **Scanner Configuration**: Visual setup for automated media discovery
- **Settings Panel**: AI provider configuration and license management
- **Dark/Light Themes**: Polished UI with smooth transitions

## ğŸš€ Quick Start

### Docker Deployment (Recommended)

```bash
# Clone repository
git clone https://github.com/Vasteva/MediaConverter.git
cd MediaConverter

# Create environment file
cp .env.example .env
nano .env  # Configure your settings

# Deploy with Docker Compose
docker-compose up -d

# Access web interface
open http://localhost:8091
```

### NVIDIA GPU Support

For NVIDIA GPU acceleration (NVENC encoding):

```bash
# Prerequisites: nvidia-container-toolkit installed
# See: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html

# Deploy with NVIDIA GPU support
docker compose -f docker-compose.yml -f docker-compose.nvidia.yml up -d
```

### Development Setup

```bash
# Install dependencies
go mod download
cd web && npm install

# Run development server
go run ./cmd/server
```

## ğŸ“¦ Production Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for comprehensive deployment guide including:
- GitLab CI/CD pipeline setup
- Automated builds and deployments
- Traefik integration for HTTPS
- Backup and monitoring procedures

Quick deployment to production server:
```bash
# Copy deployment script
scp deploy.sh root@your-server:/tmp/

# Run deployment
ssh root@your-server
sudo /tmp/deploy.sh
```

## ğŸ—ï¸ Project Structure

```
vastiva/
â”œâ”€â”€ cmd/server/           # Application entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/             # REST API routes
â”‚   â”œâ”€â”€ ai/              # AI provider integrations
â”‚   â”‚   â”œâ”€â”€ meta/        # Smart metadata cleaning
â”‚   â”‚   â”œâ”€â”€ search/      # Natural language search
â”‚   â”‚   â””â”€â”€ whisper/     # Subtitle generation
â”‚   â”œâ”€â”€ config/          # Configuration management
â”‚   â”œâ”€â”€ jobs/            # Job queue and workers
â”‚   â”œâ”€â”€ media/           # FFmpeg/MakeMKV wrappers
â”‚   â”œâ”€â”€ scanner/         # Automated file discovery
â”‚   â”œâ”€â”€ security/        # Path validation & masking
â”‚   â””â”€â”€ system/          # System monitoring
â”œâ”€â”€ web/                 # React frontend
â”œâ”€â”€ Dockerfile           # Multi-stage build (CPU/Intel/AMD)
â”œâ”€â”€ Dockerfile.nvidia    # NVIDIA CUDA build
â”œâ”€â”€ docker-compose.yml   # Production orchestration
â”œâ”€â”€ docker-compose.nvidia.yml  # NVIDIA GPU override
â””â”€â”€ .gitlab-ci.yml       # CI/CD pipeline
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Server port | `80` |
| `SOURCE_DIR` | Media source directory | `/storage` |
| `DEST_DIR` | Output directory | `/output` |
| `GPU_VENDOR` | GPU type (nvidia/intel/amd/cpu) | `cpu` |
| `AI_PROVIDER` | AI backend (openai/claude/gemini/ollama) | `none` |
| `AI_API_KEY` | API key for AI provider | - |
| `AI_MODEL` | AI model to use | - |
| `LICENSE_KEY` | Vastiva Pro license key | - |
| `SCANNER_ENABLED` | Enable automatic scanning | `false` |
| `SCANNER_MODE` | Scan mode (watch/periodic/hybrid) | `manual` |

### AI Provider Setup

**OpenAI (Recommended for all features)**
```env
AI_PROVIDER=openai
AI_API_KEY=sk-your-key-here
AI_MODEL=gpt-4
```

**Ollama (Local, no transcription)**
```env
AI_PROVIDER=ollama
AI_ENDPOINT=http://localhost:11434
AI_MODEL=llama2
```

**Claude (No transcription support)**
```env
AI_PROVIDER=claude
AI_API_KEY=sk-ant-your-key
AI_MODEL=claude-3-opus-20240229
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `GET` | `/api/stats` | System statistics |
| `GET` | `/api/dashboard/stats` | AI insights and analytics |
| `GET` | `/api/jobs` | List all jobs |
| `POST` | `/api/jobs` | Create new job |
| `DELETE` | `/api/jobs/:id` | Cancel job |
| `GET` | `/api/config` | Get system configuration |
| `POST` | `/api/config` | Update configuration |
| `GET` | `/api/scanner/config` | Get scanner settings |
| `POST` | `/api/scanner/config` | Update scanner |
| `GET` | `/api/search?q=query` | Natural language search |

## ğŸ”’ Security

- **Path Sandboxing**: All file operations restricted to configured directories
- **Credential Masking**: API keys and licenses masked in responses
- **Input Validation**: Strict validation on all user inputs
- **HTTPS Support**: Traefik integration for automatic SSL certificates

See [SECURITY_AUDIT.md](SECURITY_AUDIT.md) for detailed security analysis.

## ğŸ“Š Monitoring

### View Logs
```bash
docker-compose logs -f vastiva
```

### Check Container Status
```bash
docker-compose ps
```

### System Resources
Access the dashboard at `/` for real-time CPU, memory, GPU, and disk metrics.

## ğŸ› ï¸ Troubleshooting

### GPU Not Detected
```bash
# Verify GPU device
ls -la /dev/dri

# Check GPU vendor setting
docker-compose exec vastiva env | grep GPU_VENDOR
```

### AI Features Not Working
```bash
# Verify AI configuration
docker-compose exec vastiva env | grep AI_

# Check license status
curl http://localhost:8091/api/config | jq '.isPremium'
```

### Scanner Not Running
```bash
# Check scanner configuration
curl http://localhost:8091/api/scanner/config | jq

# Verify watch directories exist and are accessible
```

## ğŸ“š Documentation

- [Deployment Guide](DEPLOYMENT.md) - Production deployment and CI/CD
- [Security Audit](SECURITY_AUDIT.md) - Security analysis and hardening
- [Media Processing](internal/media/README.md) - FFmpeg integration details
- [File Scanner](internal/scanner/README.md) - Automated discovery system

## ğŸ¯ Roadmap

- [x] Core transcoding engine
- [x] Hardware acceleration
- [x] Job queue system
- [x] Web interface
- [x] AI metadata cleaning
- [x] AI adaptive encoding
- [x] Whisper subtitles
- [x] AI upscaling
- [x] Natural language search
- [x] AI-enhanced dashboard
- [x] CI/CD pipeline
- [ ] Multi-user support
- [ ] Advanced scheduling
- [ ] Webhook notifications

## ğŸ“„ License

GPL v3

---

**Built with â¤ï¸ using Go, React, and AI**
